% %隐层个数及训练次数可以在定义网络时自己设定，图形的话是系统自己生成的.
% %题目的意思是00得到0，01得到1,10得到1,11得到0。前者为输入，后者为输出.?
% %所以就这样构造:?
% %输入?一共四组，每组两个?
% p=[0,0;0,1;1,0;1,1];
% %输出：?
% t=[0,1,1,0];
% %构造神经网络:
% net=newff(p',t,{10},{'tansig'},'trainlm');
% %上面这句话的意思是建立新的神经网络net，newff(输入，输出，{隐层数量及该层的节点个数}，{传输函数名}，训练函数)；{10}代表单隐层，并且该层节点为10个，如果想显示多隐层，比如双隐层，{10,15}这样就行，传输函数也要相应增加，比如{'tansig','logsig'}节点数和传输函数名可以随意调整，目的当然是让预测结果更精确??
% %之后，?
% net.trainParam.goal=0.00001;%设置精确度?
% net.trainParam.epochs=5000;%设置训练次数，5000次?????
% [net,tr]=train(net,p',t);%训练开始??。。。。。。。。?
% %这样就可以训练了,过几秒后图片matlab会自动生成?
% %最后想测试训练结果的话，比如你想打00进去看它是不是也给0
% p=[0 0];
% a=sim(net,p')%  。。。sim就是让net去预测结果     
% epochs: 100 % 最大训练次数   
% goal: 0 % 训练目标    
% max_fail: 5%   最多验证失败次数
% mem_reduc: 1 %  Factor to use for memory/speed trade off   
% min_grad: 1.0000e-010 %最小训练梯度  
% mu: 1.0000e-003 %mu初始参数      
% mu_dec: 0.1000 %mu减少因子   
% mu_inc: 10 %mu增加因子  
% mu_max: 1.0000e+010%  mu最大可取 
% show: 25%   最多显示训练步数  
% time: Inf %   最多训练时间，无限制 
% minmax(P_train)%得到矩阵P_train的最小和最大值（找到每行的最小和最大，有多少行就有多少对最小和最大）；   
% %[17,3]意思是在隐层建立17个神经元，输出层建立一个神经元；
% %'tansig','logsig'},'traingdm'是神经网络的一些算法； 
% %做BP网络的话，大概要用到 
% %newff,  建立BP
% %init   网络初始化 
% %train  网络训练 
% %sim   仿真  
% %记得还要数据归一化啊  
% %追问  能给上面的数据给个代码么？谢谢啊  
% %回答  
% %P_pix=[ 175.8728234  67  0.380957096 0.270238095
% 149.5075249  113 0.7558148   0.370238095
% 155.1104445  145 0.934817771 0.46547619 
% 151.5008251   95  0.627059291 0.610714286      
% 163.4778272  60  0.36702225  0.754761905 
% 219.5723116  72  0.327910197 0.257142857   
% 176.356725   119 0.674768711 0.351190476   
% 139.7621988  185 1.323676942 0.489285714     
% 162.3837191  126 0.775939858 0.642857143     
% 175.2430455  70  0.399445238 0.742857143     
% 207.9933893  98  0.471168821 0.280952381     
% 140.0357097  116 0.828360139 0.357142857     
% 139.3646297  131 0.939980254 0.48452381 
% 138.1828499   125 0.904598509 0.632142857          
% 175.5874268  67  0.381576296 0.741666667]; 
% t=[1 0 0;1 1 0; 0 1 0; 0 1 1; 0 0 1;1 0 0;1 1 0; 0 1 0; 0 1 1; 0 0 1;1 0 0;1 1 0; 0 1 0; 0 1 1; 0 0 1];  
% t_train=t';
% P_train=P_pix';
% P_min_max=minmax(P_train);
% for n1=1:15 
%     P_train(1,n1)=(P_train(1,n1)-P_min_max(1,1))/(P_min_max(1,2)-P_min_max(1,1));  
%     P_train(2,n1)=(P_train(2,n1)-P_min_max(2,1))/(P_min_max(2,2)-P_min_max(2,1)); 
% end
% net = newff(minmax(P_train),[17,3],{'tansig','logsig'},'trainbfg');
% net=init(net); 
% net.trainparam.epochs=5000;
% net.trainparam.show=1000
% net.trainparam.goal=1e-7;
% net=train(net,P_train,t_train);
% P_pix_n=[169.0473307  72  0.42591622  0.25952381   
%     142.1908928   126 0.886132702 0.371428571   
%     148.982568   128 0.859160919 0.50952381     
%     148.5 96  0.646464646 0.60952381      
%     167.002994    68  0.407178329 0.742857143];
% P_pix_n=P_pix_n';
% for n1=1:5           
%     P_pix_n(1,n1)=(P_pix_n(1,n1)-P_min_max(1,1))/(P_min_max(1,2)-P_min_max(1,1)); 
%     P_pix_n(2,n1)=(P_pix_n(2,n1)-P_min_max(2,1))/(P_min_max(2,2)-P_min_max(2,1));
% end
% sim(net,P_pix_n)  
% %结果是
% ans =       
% 1.0000    0.9789    0.0002    0.0000    0.0000 
% 0.0282    1.0000    1.0000    0.9999    0.0000   
% 0.0000    0.0000    0.0056    0.9998    1.0000